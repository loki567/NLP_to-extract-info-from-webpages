{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2730da45-3378-44f7-bc4e-74bfc478d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from glob import glob\n",
    "import re\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22618d-c8c6-4c63-8b13-bd0ff4240afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting text from articles and storing in a dictionary with keys as file_URL_id\n",
    "\n",
    "articles = pd.read_excel(\"Input.xlsx\")\n",
    "files = {}\n",
    "\n",
    "for index,url_ in enumerate(articles['URL']):\n",
    "    response = requests.get(url_)\n",
    "    files[f\"file{index+37}\"] = \"\"\n",
    "    if response.status_code != 404:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        title = soup.find(\"h1\")\n",
    "        print(index+37, title.text)\n",
    "        files[f\"file{index+37}\"] = title.get_text()+ ' '\n",
    "        div_elements = soup.find_all(\"div\", class_=\"td-post-content tagdiv-type\")\n",
    "        for div_element in div_elements:\n",
    "            if div_element.p != None:\n",
    "                if div_element.pre != None:\n",
    "                    div_element.pre.extract()\n",
    "                files[f\"file{index+37}\"] += div_element.get_text()   # Get the text content of each div element\n",
    "                class1+=1\n",
    "        else:\n",
    "            div_elements = soup.find_all(\"div\", class_=\"tdb-block-inner td-fix-index\")\n",
    "            for div_element in div_elements:\n",
    "                if div_element.p != None:\n",
    "                    if div_element.pre != None:\n",
    "                        div_element.pre.extract()\n",
    "                    files[f\"file{index+37}\"] += div_element.get_text() # Get the text content of each div element\n",
    "                    class2+=1\n",
    "    else:\n",
    "        print(index+37,\"Error: The request failed.\")\n",
    "        error+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea567538-59ae-4e1a-b787-cfe77bf05dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding output variables\n",
    "\n",
    "def count_syllables(word):\n",
    "    # Count the number of vowels in the word.\n",
    "    num_vowels = len(re.findall(r'[aeiou]', word.lower()))\n",
    "\n",
    "    # Handle exceptions like words ending with \"es\" or \"ed\".\n",
    "    if word.endswith('es') or word.endswith('ed'):\n",
    "        num_vowels -= 1\n",
    "    # Return the number of syllables in the word.\n",
    "    return num_vowels\n",
    "\n",
    "def count_personal_pronouns(text):\n",
    "    # Create a regular expression to match personal pronouns.\n",
    "    pattern = re.compile(r'\\b(I|we|my|ours|our|your|yours|(?-i:us))\\b', re.I)\n",
    "\n",
    "    # Count the number of matches.\n",
    "    count = len(re.findall(pattern, text))\n",
    "\n",
    "    # Return the count.\n",
    "    return count\n",
    "\n",
    "\n",
    "# STOP WORDS LIST\n",
    "stop_words = \"\"\n",
    "stop_words_path_pattern = \"StopWords\\\\StopWords_*.txt\"\n",
    "stop_words_files = glob(stop_words_path_pattern)\n",
    "for stop_words_file in stop_words_files:\n",
    "    with open(stop_words_file, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        stop_words += file.read()\n",
    "stop_words_list = set(stop_words.lower().split())\n",
    "sorted_stop_words_list = sorted(stop_words_list)\n",
    "\n",
    "# POSITIVE WORDS LIST\n",
    "pos_words_path = \"MasterDictionary\\\\positive-words.txt\"\n",
    "with open(pos_words_path,\"r\") as pos:\n",
    "    sorted_positive_words = pos.read().lower().split()\n",
    "\n",
    "# NEGATIVE WORDS LIST\n",
    "neg_words_path = \"MasterDictionary\\\\negative-words.txt\"\n",
    "with open(neg_words_path,\"r\") as neg:\n",
    "    sorted_negative_words = neg.read().lower().split()\n",
    "\n",
    "# SCORES\n",
    "positive_score = 0\n",
    "negative_score = 0\n",
    "polarity_score = 0\n",
    "remain = 0\n",
    "total_words = 0 \n",
    "total_sent = 0\n",
    "complex_words = []\n",
    "avg_word_length = 0\n",
    "personal_pronouns = 0\n",
    "total_syllables_count = 0\n",
    "\n",
    "output = {\"POSITIVE SCORE\":[],\"NEGATIVE SCORE\":[],\"POLARITY SCORE\":[],\"SUBJECTIVITY SCORE\":[],\"AVG SENTENCE LENGTH\":[],\\\n",
    "          \"PERCENTAGE OF COMPLEX WORDS\":[],\"FOG INDEX\":[],\"AVG NUMBER OF WORDS PER SENTENCE\":[],\"COMPLEX WORD COUNT\":[]\\\n",
    "          ,\"WORD COUNT\":[],\"SYLLABLE PER WORD\":[],\"PERSONAL PRONOUNS\":[],\"AVG WORD LENGTH\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20540a38-e638-46b1-8e84-6ff1d0bbf765",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    final_text = []\n",
    "    text = files[file]\n",
    "    personal_pronouns = count_personal_pronouns(text)\n",
    "    text_words_punctn = nltk.word_tokenize(text.lower())\n",
    "    text_words = [word for word in text_words_punctn if not re.match(r'[.,|?!0-9]', word)]\n",
    "    text_length = sum(len(word) for word in text_words)\n",
    "    total_words = len(text_words)\n",
    "    text_sent = nltk.sent_tokenize(text)\n",
    "    total_sent = len(text_sent)\n",
    "    if text_words != None:\n",
    "        for word in text_words:\n",
    "            total_syllables_count+=count_syllables(word)\n",
    "            if (count_syllables(word)) > 2:\n",
    "                complex_words.append(word)\n",
    "            if word not in sorted_stop_words_list:\n",
    "                final_text.append(word)\n",
    "                if word in sorted_positive_words:\n",
    "                    positive_score+=1\n",
    "                elif word in sorted_negative_words:\n",
    "                    negative_score+=1\n",
    "                else:\n",
    "                    remain+=1\n",
    "            words_after_cleaning = len(final_text)\n",
    "            polarity_score = (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "            subjectivity_score = (positive_score + negative_score)/ ((words_after_cleaning) + 0.000001)\n",
    "            avg_sent_length = total_words/total_sent\n",
    "            complex_words_count = len(complex_words)\n",
    "            avg_word_length = text_length/total_words\n",
    "            percent_of_complex_words = complex_words_count/total_words\n",
    "            fog_index = 0.4*(avg_sent_length+percent_of_complex_words)\n",
    "            syllable_per_word = total_syllables_count/total_words\n",
    "        output[\"POSITIVE SCORE\"].append(positive_score)\n",
    "        output[\"NEGATIVE SCORE\"].append(negative_score)\n",
    "        output[\"POLARITY SCORE\"].append(polarity_score)\n",
    "        output[\"SUBJECTIVITY SCORE\"].append(subjectivity_score)\n",
    "        output[\"AVG SENTENCE LENGTH\"].append(avg_sent_length)\n",
    "        output[\"PERCENTAGE OF COMPLEX WORDS\"].append(percent_of_complex_words)\n",
    "        output[\"FOG INDEX\"].append(fog_index)\n",
    "        output[\"AVG NUMBER OF WORDS PER SENTENCE\"].append(avg_sent_length)\n",
    "        output[\"COMPLEX WORD COUNT\"].append(complex_words_count)\n",
    "        output[\"WORD COUNT\"].append(words_after_cleaning)\n",
    "        output[\"SYLLABLE PER WORD\"].append(syllable_per_word)\n",
    "        output[\"PERSONAL PRONOUNS\"].append(personal_pronouns)\n",
    "        output[\"AVG WORD LENGTH\"].append(avg_word_length)\n",
    "        print(file,\"complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958262d-40a2-4f4c-90f0-3170f004f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data in output dictionary to excel file\n",
    "\n",
    "wb = openpyxl.load_workbook(\"Output Data Structure.xlsx\")\n",
    "\n",
    "sheet = wb.active\n",
    "\n",
    "for col in range(3, 16):\n",
    "    for row in range(2, 110):\n",
    "        char = chr(64 + col)\n",
    "        keys = list(output.keys())\n",
    "        col_index = keys[col-3]\n",
    "        \n",
    "        sheet[char+str(row)] = round(output[col_index][row-2],2)\n",
    "wb.save(\"Output Data Structure.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7299392-fe49-4663-ab83-4542db16079f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345d4f2-dd39-470f-8461-ebb8b2d6b9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23549457-d5fc-49ef-b389-e00e606623e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777b9a3-8b31-405e-8ff4-0d1307edb6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
